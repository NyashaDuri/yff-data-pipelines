# Pipelines

The pipelines are orchestrated using [DVC](https://dvc.org).

## Current dependency graph

[![](https://mermaid.ink/img/pako:eNqVlE9TwjAQxb8KkzNRUEDpwZNHvehN62FJtm2GJNtJUpkOw3c3QBnsHxzpKX3J7032dbdbJkgiS1imaSMKcGH08pbaUfPYuDn9TFmpStTKor-V3-KmBqMTUaBY84wcLyFHXpUSAvqUfbXpuxYt0Prql4mkjdUEkh83evT9n3TpSKD3l-BZG9agDNgwxJ-2ehbz4dotGeX56fI9ajFMBafyHB33KiCPaUEPfGiBGlZUOW7ArTEMZJY5MvxwlZ7R41VGev_lAjdkQ6HrntnyP2anLBuvVc1LQbbnNZ1cZWYGGorzp0NrdDqlkRedHhiW54086-TfyMtOmo08nXSCGTafTi7o7UlSNothKbLnunMMsV42ZgadASXjXG73HikLBRpMWRKXEjOodDyY2l08ClWg99oKFvurwjE7DuKzgtyBYUkG2ke1BPtBdH5HqQK51-PsH34Bux_IfFXn?type=png)](https://mermaid.live/edit#pako:eNqVlE9TwjAQxb8KkzNRUEDpwZNHvehN62FJtm2GJNtJUpkOw3c3QBnsHxzpKX3J7032dbdbJkgiS1imaSMKcGH08pbaUfPYuDn9TFmpStTKor-V3-KmBqMTUaBY84wcLyFHXpUSAvqUfbXpuxYt0Prql4mkjdUEkh83evT9n3TpSKD3l-BZG9agDNgwxJ-2ehbz4dotGeX56fI9ajFMBafyHB33KiCPaUEPfGiBGlZUOW7ArTEMZJY5MvxwlZ7R41VGev_lAjdkQ6HrntnyP2anLBuvVc1LQbbnNZ1cZWYGGorzp0NrdDqlkRedHhiW54086-TfyMtOmo08nXSCGTafTi7o7UlSNothKbLnunMMsV42ZgadASXjXG73HikLBRpMWRKXEjOodDyY2l08ClWg99oKFvurwjE7DuKzgtyBYUkG2ke1BPtBdH5HqQK51-PsH34Bux_IfFXn)

> This has been generated by running `dvc dag --mermaid` and copying the result into https://mermaid.live/. _NB_ changing the flowchart direction from `TD` to `LR` seems to render a better chart.

## Pipeline automation

These are automated by the [`pipeline` GitHub action](../.github/workflows/pipeline.yml).

It is currently scheduled to run every weekday at 06:20, 07:20, 08:20 and 09:20, using the cron string [20 6-9 * * 1-5](https://crontab.guru/#20_6-9_*_*_1-5). It can also be triggered manually on the [`pipeline` page on GitHub](https://github.com/open-innovations/yff-data-pipelines/actions/workflows/pipeline.yml).

## Outbound triggers

The stage [pipelines/dvc.yaml:trigger-site-build](../pipelines/dvc.yaml) watches for any changes in `data/processed` and `data/metadata` and uses a GitHub Repository Dispatch trigger to cause the [Update data action](https://github.com/open-innovations/yff-data/actions/workflows/update-data.yml) to run on the YFF Data site repository. This means that as the data changes in this repository, it will immediately start a build in the data pipeline, which will in turn trigger a build in the site.

_NB_ There is a slight possiblity that the build of the pipeline will start working before the update from the site has been committed to this repository. This would mean the data is not available to the site build[^1]. This is being monitoried for the next run to see how problematic it becomes. 


[^1]: There are ways around this, using a conditional GitHub action step which triggers only if the commit step triggers.
